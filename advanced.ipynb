{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run code/undistort\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "objpoints, imgpoints = prepare_obj_img_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1305b0898>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "img = cv2.imread('test_images/test1.jpg')\n",
    "undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "plt.imshow(cv2.cvtColor(undistorted, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "\n",
    "undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12f8dc9b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run code/color_and_gradient_threshed\n",
    "img = cv2.imread('test_images/test1.jpg')\n",
    "undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "binary_img = threshed_binary_pipeline(undistorted, s_thresh=(100, 255), sx_thresh=(30, 100))\n",
    "plt.imshow(binary_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 595.       460.     ]\n",
      " [ 213.33333  720.     ]\n",
      " [1196.6666   720.     ]\n",
      " [ 735.       460.     ]] [[320.   0.]\n",
      " [320. 720.]\n",
      " [960. 720.]\n",
      " [960.   0.]]\n"
     ]
    }
   ],
   "source": [
    "%run code/perspective_transform\n",
    "\n",
    "img = cv2.imread('test_images/test1.jpg')\n",
    "undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "img_size = (undistorted.shape[1], undistorted.shape[0])\n",
    "src = np.float32(\n",
    "    [[(img_size[0] / 2) - 45, img_size[1] / 2 + 100],\n",
    "    [((img_size[0] / 6)), img_size[1]],\n",
    "    [(img_size[0] * 5 / 6) + 130, img_size[1]],\n",
    "    [(img_size[0] / 2 + 95), img_size[1] / 2 + 100]])\n",
    "dst = np.float32(\n",
    "    [[(img_size[0] / 4), 0],\n",
    "    [(img_size[0] / 4), img_size[1]],\n",
    "    [(img_size[0] * 3 / 4), img_size[1]],\n",
    "    [(img_size[0] * 3 / 4), 0]])\n",
    "print(src, dst)\n",
    "transformed = warper(undistorted, src, dst)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(with_points_drawn(cv2.cvtColor(undistorted, cv2.COLOR_BGR2RGB), src))\n",
    "ax1.set_title('Undistorted image with src points draw', fontsize=30)\n",
    "ax2.imshow(with_points_drawn(cv2.cvtColor(transformed, cv2.COLOR_BGR2RGB), dst))\n",
    "ax2.set_title('Warped result with dst points drawn', fontsize=30)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1280922e8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run code/perspective_transform\n",
    "\n",
    "img = cv2.imread('test_images/test3.jpg')\n",
    "undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "binary_img = threshed_binary_pipeline(undistorted, s_thresh=(100, 255), sx_thresh=(30, 100))\n",
    "img_size = (undistorted.shape[1], undistorted.shape[0])\n",
    "src = np.float32(\n",
    "    [[(img_size[0] / 2) - 45, img_size[1] / 2 + 100],\n",
    "    [((img_size[0] / 6)), img_size[1]],\n",
    "    [(img_size[0] * 5 / 6) + 130, img_size[1]],\n",
    "    [(img_size[0] / 2 + 95), img_size[1] / 2 + 100]])\n",
    "dst = np.float32(\n",
    "    [[(img_size[0] / 4), 0],\n",
    "    [(img_size[0] / 4), img_size[1]],\n",
    "    [(img_size[0] * 3 / 4), img_size[1]],\n",
    "    [(img_size[0] * 3 / 4), 0]])\n",
    "\n",
    "binary_warped = warper(binary_img, src, dst)\n",
    "\n",
    "plt.imshow(binary_warped, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12f37fac8>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hist(img):\n",
    "    # Grab only the bottom half of the image\n",
    "    # Lane lines are likely to be mostly vertical nearest to the car\n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "\n",
    "    # Sum across image pixels vertically - make sure to set `axis`\n",
    "    # i.e. the highest areas of vertical lines should be larger values\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "# Create histogram of image binary activations\n",
    "histogram = hist(binary_warped)\n",
    "\n",
    "# Visualize the resulting histogram\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x130e1e8d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run code/lane_pixel_finder\n",
    "%run code/fit_polynomial\n",
    "\n",
    "leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "left_fitx, right_fitx, ploty, _, _ = fit_polynomial(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "\n",
    "## Visualization ##\n",
    "# Colors in the left and right lane regions\n",
    "out_img[lefty, leftx] = [255, 0, 0]\n",
    "out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "# Plots the left and right polynomials on the lane lines\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "# print(out_img.shape)\n",
    "# print(np.average(leftx) - np.average(rightx))\n",
    "plt.imshow(out_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12f8a6e10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Polynomial fit values from the previous frame\n",
    "# Make sure to grab the actual values from the previous step in your project!\n",
    "left_fit = np.array([ 2.13935315e-04, -3.77507980e-01,  4.76902175e+02])\n",
    "right_fit = np.array([4.17622148e-04, -4.93848953e-01,  1.11806170e+03])\n",
    "\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "     ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty\n",
    "\n",
    "def search_around_poly(binary_warped):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "#     cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "#     cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ## End visualization steps ##\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run image through the pipeline\n",
    "# Note that in your project, you'll also want to feed in the previous fits\n",
    "result = search_around_poly(binary_warped)\n",
    "\n",
    "# View your output\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4939.961188205417 3085.399900450413\n"
     ]
    }
   ],
   "source": [
    "%run code/lane_pixel_finder\n",
    "\n",
    "def measure_curvature_pixels():\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in pixels.\n",
    "    '''\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "    \n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    \n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ##### Calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "\n",
    "# Calculate the radius of curvature in pixels for both lane lines\n",
    "left_curverad, right_curverad = measure_curvature_pixels()\n",
    "\n",
    "print(left_curverad, right_curverad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1621.6758558391496 m -0.06088471353554814 m\n"
     ]
    }
   ],
   "source": [
    "%run code/curvature_and_offset\n",
    "\n",
    "leftx, lefty, rightx, righty, _ = find_lane_pixels(binary_warped)\n",
    "# Calculate the radius of curvature and offset from the middle of in meters\n",
    "left_curverad, left_fit_cr = measure_curvature_real_with_pixels(binary_warped.shape, leftx, lefty)\n",
    "right_curverad, right_fit_cr = measure_curvature_real_with_pixels(binary_warped.shape, rightx, righty)\n",
    "offset = measure_offset_real(binary_warped.shape, left_fit_cr, right_fit_cr)\n",
    "print(left_curverad, 'm', offset, 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13074a9e8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run code/lane_pixel_finder\n",
    "%run code/fit_polynomial\n",
    "%run code/curvature_and_offset\n",
    "\n",
    "def mark_lane(binary_warped, img, undistorted):\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "    left_fitx, right_fitx, ploty, _, _ = fit_polynomial(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistorted, 1, newwarp, 0.3, 0)\n",
    "    return result\n",
    "\n",
    "# result = img\n",
    "result = mark_lane(binary_warped, img, undistorted)\n",
    "\n",
    "# Calculate the radius of curvature and offset from the middle of in meters\n",
    "left_curverad, left_fit_cr = measure_curvature_real_with_pixels(binary_warped.shape, leftx, lefty)\n",
    "right_curverad, right_fit_cr = measure_curvature_real_with_pixels(binary_warped.shape, rightx, righty)\n",
    "offset = measure_offset_real(binary_warped.shape, left_fit_cr, right_fit_cr)\n",
    "\n",
    "if offset >= 0:\n",
    "    direction = 'right'\n",
    "else:\n",
    "    direction = 'left'\n",
    "\n",
    "font                   = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "fontScale              = 2\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2\n",
    "radius_text = \"Radius of curvature = %.0f(m)\" % left_curverad\n",
    "cv2.putText(result, radius_text, (100, 50), font, fontScale, fontColor, lineType)\n",
    "offset_text = \"Vehicle is %.2fm %s of center\" % (np.absolute(offset), direction)\n",
    "cv2.putText(result, offset_text, (100, 90), font, fontScale, fontColor, lineType)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run code/undistort\n",
    "%run code/perspective_transform\n",
    "\n",
    "def process_image_orig(img):\n",
    "    undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "    binary_img = threshed_binary_pipeline(undistorted, s_thresh=(100, 255), sx_thresh=(30, 100))\n",
    "    img_size = (undistorted.shape[1], undistorted.shape[0])\n",
    "    src = np.float32(\n",
    "        [[(img_size[0] / 2) - 45, img_size[1] / 2 + 100],\n",
    "        [((img_size[0] / 6)), img_size[1]],\n",
    "        [(img_size[0] * 5 / 6) + 130, img_size[1]],\n",
    "        [(img_size[0] / 2 + 95), img_size[1] / 2 + 100]])\n",
    "    dst = np.float32(\n",
    "        [[(img_size[0] / 4), 0],\n",
    "        [(img_size[0] / 4), img_size[1]],\n",
    "        [(img_size[0] * 3 / 4), img_size[1]],\n",
    "        [(img_size[0] * 3 / 4), 0]])\n",
    "\n",
    "    binary_warped = warper(binary_img, src, dst)\n",
    "    result = mark_lane(binary_warped, img, undistorted)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run code/pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoFileClip(\"project_video.mp4\").save_frame('my_image.jpg', t=29)\n",
    "init_lines()\n",
    "process_image(cv2.imread('my_image.jpg'))\n",
    "\n",
    "VideoFileClip(\"project_video.mp4\").save_frame('my_image.jpg', t=30)\n",
    "process_image(cv2.imread('my_image.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video = 'project_video_output2.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(28,30)\n",
    "init_lines()\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video_output2.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video = 'project_video_output.mp4'\n",
    "# clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,2)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "init_lines()\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run code/pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output_video = 'challenge_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\").subclip(3,5)\n",
    "init_lines()\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(output_video, audio=False)\n",
    "\n",
    "# VideoFileClip(\"challenge_video.mp4\").save_frame('my_image.jpg', t=0)\n",
    "# image = cv2.imread('my_image.jpg')\n",
    "# init_lines()\n",
    "# output = process_image(image)\n",
    "\n",
    "# left_line, right_line = get_lines()\n",
    "\n",
    "# VideoFileClip(\"challenge_video.mp4\").save_frame('my_image.jpg', t=30)\n",
    "# process_image(cv2.imread('my_image.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"challenge_video_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
